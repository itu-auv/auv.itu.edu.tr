[
    {
        "id": 1,
        "title": "A Small Screw, A Big Lesson: Why Our ESC Board Burned Out",
        "author": "Mehmet Erkılıç",
        "date": "2025-04-11",
        "sub_team": "Electronics",
        "image": "images/blog/esc_vida.jpeg",
        "content": "<p>The ESC boards we use to control the motors in our AUV vehicle are securely housed inside an ESC case. However, a few months ago, we experienced an incident that taught us all a valuable lesson.</p><p>While our mechanical team was assembling the ESC case, they accidentally dropped a screw inside without realizing it. This small screw caused a short circuit on the board, rendering it completely unusable. At first, we assumed the issue was caused by a single component and tried replacing parts one by one in search of a solution. But no matter what we did, we couldn't get it working again.</p><p>Eventually, we discovered that the problem wasn't limited to a single component — the entire board was damaged. A screw falling into the wrong place had led to the complete destruction of the ESC board.</p><p>This experience taught us not only the importance of being careful, but also how crucial accurate diagnosis is. After identifying the issue, we redesigned the board, had it manufactured, and finally brought it back to life.</p><p>Sometimes, the biggest problems are hidden in the smallest details. We learned an important lesson from this process: \"Final checks during assembly are just as critical as the design itself.\"</p>",
        "slug": "esc-board-burned-out"
    },
    {
        "id": 2,
        "title": "Developments in Taluy Mini Embedded Software",
        "author": "Taşkın Ökmen",
        "date": "2025-03-08",
        "sub_team": "Electronics",
        "image": "images/blog/mini_gomulu.jpeg",
        "content": "<p>In this article, I will talk about the developments in the embedded software of our new vehicle, Taluy Mini.</p><p>The main board on the Taluy Mini AUV integrates all repetitive tasks such as sensor readings and continuous processing of raw data, power distribution to the integrated circuits on the board with the required voltage, and PWM generation for driving the motors — effectively abstracting these operations from the main computer and consolidating them into a single board. This allowed us to avoid using multiple microcontrollers and the additional delay caused by communication between microcontrollers. Moreover, by offloading some of the main computer's workload to the main board, we enabled the main computer to be used more efficiently for core competition tasks.</p><p>To manage sensor readings on the board, driving the brushless DC motors, sending ROS packages to the main computer via Ethernet, and executing the other ongoing tasks of the main board concurrently, we developed our own RTOS library. AUV-RTOS includes a simple round-robin scheduler and ensures that the tasks on the vehicle are performed with low latency and at the desired intervals.</p><p>In our new vehicle, we used the BNO055 as the IMU sensor. We chose BNO due to its ability to provide absolute orientation and perform sensor fusion thanks to the onboard ARM Cortex-M0+. We tested and calibrated the IMU sensor using rviz — ROS's 3D simulation tool. We also developed our own driver software to decode the messages from the Navquest Micro600 DVL sensor, which is connected to the main board. Thanks to the MAX232 integrated circuit on the main board, we converted the UART output voltage level of the microcontroller to the RS-232 voltage level required for communication with the DVL sensor, enabling successful communication between the DVL and the main board.</p><p>Another difference between the Taluy Mini main board and the Taluy expansion board is that it uses Ethernet instead of UART to communicate with the main computer. For network and transport layers over Ethernet, we used the lwIP TCP/IPv4 stack library, commonly used in embedded systems, and the Ethernet API of rosserial to communicate with the main computer via ROS packages. Due to Ethernet's CRC32 error detection and feedback features between host and client, we transitioned from UART to Ethernet communication on the main board.</p>",
        "slug": "taluy-mini-embedded-software"
    },
    {
        "id": 3,
        "title": "Expansion Board: A Mistake, A Step Forward",
        "author": "Ravza Betül Karakaş",
        "date": "2025-02-15",
        "sub_team": "Electronics",
        "image": "images/blog/eski_expansion.jpeg",
        "content": "<p>In our vehicle, we use the CAN Bus protocol for communication between custom-designed boards, which we developed based on the specific needs of our system. Each board includes an integrated CAN transceiver, allowing for reliable and stable communication across the system.</p><p>However, one of the key components of our system, the Jetson, does not have built-in support for CAN transceivers. To bridge this gap, we designed an expansion board that acts as an interface between the Jetson and the vehicle's CAN network. This expansion board receives CAN signals and transmits them to the Jetson via rosserial, enabling seamless communication between the Jetson and other system modules.</p><p>Everything was working smoothly—until a mishap during pre-pool test preparations. The expansion board was accidentally inserted into the Jetson in the wrong orientation, causing the onboard chip to burn out.</p><p>Following this unfortunate incident, we not only repaired the damaged board but also decided to revisit our design. As part of this process, we are upgrading from the STM32F103 chip to the more powerful and faster STM32F446. This new chip provides us with greater flexibility in terms of processing power and peripheral support, which will better meet the evolving demands of our system.</p>",
        "slug": "expansion-board-mistake"
    },
    {
        "id": 10,
        "title": "Underwater Teams United at One Table",
        "author": "Zeynep Demirbaş",
        "date": "2025-02-10",
        "sub_team": "Business Operations",
        "image": "images/blog/blog_zeynep_eng.jpeg",
        "content": "<p>As the ITU AUV Team, we organized a breakfast event on our campus to bring together high school and university teams working in the underwater field across Turkey.</p><p>Our goal in organizing this event was to enable students working in the underwater domain to meet each other, share their experiences, and create a communication network where they can support one another.</p><p>The event started with a warm breakfast atmosphere, followed by conversations about each team's vehicles and the challenges they've faced. We then moved to our workshop for more technical, hands-on discussions about the vehicles. Later in the day, underwater-themed games we played made the atmosphere even warmer.</p><p>As the Business Operations team, we took on the responsibilities of reaching out to teams, planning the event, and maintaining communication afterward. At the end of the event, we created a WhatsApp group including all participants to ensure that this connection continues beyond the event.</p><p>This gathering was not just an event for us; it was a small but valuable step toward building a vibrant community among students working in the underwater field.</p>",
        "slug": "underwater-teams-meeting"
    },
    {
        "id": 11,
        "title": "Motorized Torpedo",
        "author": "Ravza Betül Karakaş",
        "date": "2026-01-22",
        "sub_team": "Electronics",
        "image": "images/blog/motorlu_torpido.jpeg",
        "content": "<p>This year on Taluy, we are developing a motorized torpedo to experiment with a new approach. Our goal is to create an experimental system that can propel itself for a certain duration after separating from the vehicle. While mounted on the vehicle, the torpedo charges its supercapacitor through wireless charging. After launch, the energy stored in the supercapacitor powers the motor, enabling the torpedo to advance. The system is triggered by a reed relay, as in our previous designs. How long the torpedo operates is determined by an adjustable timer on the circuit. The electrical design—covering motor driving, wireless charging, and supercapacitor charge–discharge paths—is largely complete. Integration and testing of the system are currently underway.</p>",
        "slug": "motorlu-torpido"
    },
    {
        "id": 12,
        "title": "Architectural Simplification in In-Vehicle Communication",
        "author": "Tolga Öztürk",
        "date": "2026-01-05",
        "sub_team": "Electronics",
        "image": "images/blog/expansion.jpeg",
        "content": "<p>This year on Taluy, we took an important step toward simplifying the in-vehicle communication architecture. Traditionally, each subsystem had its own communication interface, which increased overall system complexity. To address this issue, we developed an architecture that connects all subsystems through a single communication bus. This approach provided significant benefits on both the hardware and software sides. On the hardware side, we achieved less wiring and a simpler PCB design. On the software side, by abstracting the communication layer, we enabled each subsystem to focus on its own internal logic. As a result, we accelerated the development process while also improving system reliability.</p>",
        "slug": "yeni-blog-sayfasi"
    },
    {
        "id": 4,
        "title": "Acoustic Localization",
        "author": "Seren Sıla Uysal",
        "date": "2024-07-03",
        "sub_team": "Software",
        "image": "images/blog/006.jpg",
        "content": "<p>In this post, we are going to dive into (pun intended) one of the assignments that is given to the software team members last season. In this assignment, we tackled the challenge of pinpointing the precise location and depth of an underwater pinger (acoustic transmitter) using acoustic localization techniques. The data provided in a file called data.csv was our starting point, containing vital measurements taken with multiple acoustic sensors. These measurements include the GPS coordinates of the sensors, the depth of the sensors from the water surface, and the distances from the sensors to the pinger. Our task was to use these data points to determine the exact latitude, longitude, and depth of the pinger.</p><p>First, we dove into the data processing phase. We read the data from data.csv, adjusting the distance values by multiplying them by two for accurate calculations. We then extracted the latitude, longitude, and depth columns as centers, and the distance column as radii.</p><p>Next, we defined the Haversine formula, which calculates the distance between two points on a sphere. This formula was essential for our calculations, considering the Earth's curvature.</p><p>We then moved on to the residuals function, which calculates the sum of squared differences between the calculated radius and the known radius. This function was crucial for optimizing our calculations.</p><p>For the optimization process, we started with an initial guess, calculated as the mean of the centers array. Using the least squares method, we aimed to find the intersection point of the spheres representing sensor measurements. This process helped us estimate the pinger's coordinates with precision.</p><p>Once we had the estimated coordinates, we created an interactive map using Folium. This map allowed us to visualize the sensor locations and the estimated pinger location. We added circles and markers for each sensor location and a distinct marker for the pinger. Finally, we saved the map as pingermap.html for easy access and review.</p><p>The result of our efforts was the estimated coordinates of the pinger, pinpointed at Latitude 42.43869 and Longitude 18.58540.</p>",
        "slug": "acoustic-localization"
    },
    {
        "id": 5,
        "title": "Passive sonar project",
        "author": "Yusuf Çalışkan",
        "date": "2024-06-14",
        "sub_team": "Electronics",
        "image": "images/blog/005.jpg",
        "content": "<p>I would like to tell you about the passive sonar project, which is one of the biggest projects I had the opportunity to work on this year. One of the most critical problems our vehicle faces in the Robosub 2024 competition it will participate in this year is that the mission areas are marked with devices called \"pingers\" that send repeated and intermittent signals at a certain frequency. In order for our vehicle to be able to achieve these tasks, it needs to be able to distinguish the mission locations by listening effectively and using the algorithm prepared for this job.</p><p>In terms of hardware, we use underwater microphones called hydrophones for this task. We pass the signals we receive from our hydrophones through our acoustic processing board (APB) and then transfer our analog signal to the digital environment, making it processable in our prepared algorithm.</p><p>In terms of software, by taking advantage of the fact that the incoming signal is in the form of a sinusoid, we divide the voltage values ​​between the peaks into PWM-like values, and by taking into account the arrival times of the different signals between these values ​​and the geometric angular positions of our hydrophones, we calculate the arrival time of the signal and the angle of arrival to our vehicle. Using this information, we can find our mission area by directing our vehicle to the signal source.</p>",
        "slug": "passive-sonar-project"
    },
    {
        "id": 6,
        "title": "Motherboard Firmware Progress",
        "author": "Nihat Arslan",
        "date": "2024-05-24",
        "sub_team": "Electronics",
        "image": "images/blog/004.jpg",
        "content": "<p>I am working on developing the embedded software for the motherboard. Since our vehicle works with ROS, we are using rosserial_arduino packet communication on the motherboard. This library essentially simulates the motherboard with a python software that acts as a bridge instead of having the host computer talk to real ROS.</p><p>Currently, ping sonars are read via the motherboard. We can turn ping sonars on and off via a ROS service. Thanks to ping sonars, we can measure the distance of objects in front of us to us at 30-degree intervals underwater. We increase the accuracy of our underwater mapping by entering this data into mathematical functions.</p><p>We can also use the torpedo firing system via our motherboard. We use this feature by calling a rosservice. Right now, when a service is called, all communications except that function stop until the function completes its function. Although this period is as short as half a second, we are working on a solution to this problem.</p><p>Finally, apart from its many features, our motherboard is actually a power distribution board with power divider circuits. In this way, we can operate our sensors that require many different voltage levels.</p>",
        "slug": "motherboard-firmware-progress"
    },
    {
        "id": 7,
        "title": "Sensor fusion on Simulink and ROS connections",
        "author": "Emre Tezel",
        "date": "2024-05-09",
        "sub_team": "Software",
        "image": "images/blog/003.jpg",
        "content": "<p>One of the projects I worked on in the AUV Software team was modeling sensor fusion algorithms via Simulink. The sensors that measure the position and orientation information of the vehicle, which are vital for autonomous movement, have a certain amount of error accumulation and noise. These errors are corrected and improved by a mathematical algorithm called the Kalman Filter, mostly by combining data from multiple sensors.</p><p>The Kalman Filter algorithm is available as a block in Simulink. After modeling the algorithm in Simulink, we can move to the ROS environment where we run the tool with the C/C++ code generation feature in Simulink. The program provides C++ code generation compatible with ROS workspaces.</p><p>Performing modeling in Simulink allows us to have a more visual and holistic view of the overall appearance of the model. The Simulink environment also makes data review and debugging processes easier for us.</p>",
        "slug": "sensor-fusion-simulink"
    },
    {
        "id": 8,
        "title": "Robotic Gripper Design Process",
        "author": "Taner Özpınar",
        "date": "2024-03-29",
        "sub_team": "Mechanic",
        "image": "images/blog/002.jpg",
        "content": "<p>Hello, I would like to tell you a little bit about our gripper design process. Before we begin, you should know that the gripper is used to manipulate objects and change their location. Let's start...</p><p>Our first design was a system with bevel gears. In this system, there were 2 gears and a pinion gear between them. The drive power was provided by a servo motor. However, when the 3D printing was done, there were problems with the tolerances and dimensions of the claws. Therefore, we had to reconsider the design and moved on to version 2.</p><p>Gripper v2: Compared to the first version, we resized the gripper and reduced the design by 125%. A tolerance of 0.3 mm was given between the claws and the necessary gaps were left on the sides by topology optimization. However, although it was suitable for vertical use due to the bevel gear system, there were problems in positioning it in the lower compartment of the vehicle due to the space taken up by the servo motor. Therefore, we moved to version 3 for horizontal use.</p><p>Gripper v3: We followed a new design strategy, designing each component parametrically and separately. In the previous design, we worked as a unified and integrated whole, which made it difficult to fix something in the later stages. This new approach made the design more modular and flexible.</p><p>I hope you liked the challenges we faced while designing the gripper and the ways we overcame them :) </p>",
        "slug": "robotic-gripper-design"
    },
    {
        "id": 9,
        "title": "New blog page!",
        "author": "Kayra Pamukçu",
        "date": "2024-03-05",
        "sub_team": "Business Operations",
        "image": "images/blog/001.jpg",
        "content": "<p>Hello, we decided to add a blog page to our site. You'll be able to see the development process of our vehicle here. Unfortunately, using a dynamic web page is not an option for us, so whenever we want to add a new blog post, we have to modify the code of the page directly. Hope to see you around in the future :)</p>",
        "slug": "new-blog-page"
    }
    ,
    {
        "id": 13,
        "title": "Tying a Carrot to the AUV | A Navigation Story",
        "author": "Emin Meydanoglu",
        "date": "2026-01-13",
        "sub_team": "Software",
        "image": "images/blog/havuc.png",
        "content": "<p>Navigation in autonomous systems is the system responsible for moving the robot safely to a determined target on the map without exploring the surroundings. In this article, we will explain the innovations we made in Taluy's navigation system and the \"Follow the Carrot\" method we developed.</p><h3><strong>One-Man Army: Align Frame Controller</strong></h3><p>The Align Frame Controller (AFC) is a simple controller developed to align any frame on the robot with an external static or moving frame. Its working logic is quite clear:</p><ol><li>The error between two frames is calculated.</li><li>This error is converted to velocity commands with a P controller.</li><li>Velocity commands are transferred to low-level controllers.</li></ol><p>Is it possible to use this simple method as an effective navigation system? For Taluy, this was exactly the method we used in the past: we would create a frame that would move at certain intervals from Taluy to the target point. This frame would proceed to the target at a constant speed that the robot could (hopefully) follow. However, since what the robot was actually doing was not taken into account, the robot often could not catch the target frame and the desired path could not be followed.</p><p>Fortunately, with a few adjustments, we could make this system much better, and we did:</p><h3>Follow the carrot</h3><p>The fundamental problem of the previous system was that the dynamic target frame ignored the robot's current state. Even if the robot was stuck in oscillation or the controllers were not working, this live frame would start moving the moment it received a signal and arrive at the target at a certain speed. For this reason, the robot often could not catch up with the target frame and experienced problems in route tracking.</p><p>We developed two main new features in the new system:</p><ol><li><p>Path-based route definition</p><p>We started creating the route the robot would follow to reach the target point in the nav_msgs/Path message type. This message type consists of a combination of ordered points. Its difference from a function curve is that each point has an orientation along with a position.</p><pre><code>nav_msgs/Path:\n\nstd_msgs/Header header\n  uint32 seq\n  time stamp\n  string frame_id\n\ngeometry_msgs/PoseStamped[] poses\n  std_msgs/Header header\n    uint32 seq\n    time stamp\n    string frame_id\n  geometry_msgs/Pose pose\n    geometry_msgs/Point position\n    geometry_msgs/Quaternion orientation</code></pre><p>In this way, the path the robot will follow is clearly defined and visualized.</p></li></ol><p><strong>2. Dynamic Target Frame Calculator</strong></p><p>We developed an algorithm that constantly takes into account the robot's current position and dynamically determines the target point on the path. The new system simply follows the steps below:</p><ol><li>Gets the robot's position and path information.</li><li>Calculates the Euclidean distances of the points on the path relative to the robot.</li><li>Selects the point closest to 1 meter distance to the robot. This means that if all points are closer than 1 meter, it selects the last element of the path (index[-1]).<ol><li>This frame is always one of the path points, or interpolated between two (because we selected from among them).</li></ol></li><li>The selected point is converted to a frame relative to the robot and given to the align frame controller.</li><li>These operations occur 20 times per second.</li></ol><p>Dynamic frame calculator function:</p><pre><code class=\"language-python\">def calculate_dynamic_target(\n    path: Path, robot_pose: PoseStamped, dynamic_target_lookahead_distance: float\n) -> Optional[PoseStamped]:\n\n    if not path.poses or dynamic_target_lookahead_distance <= 0:\n        return None\n\n    closest_index = find_closest_point_index(path, robot_pose)\n\n    # If closest to last point, return it\n    if closest_index >= len(path.poses) - 1:\n        return path.poses[-1]\n\n    # Walk along path segments until we've consumed dynamic_target_lookahead_distance\n    remaining_distance = dynamic_target_lookahead_distance\n    current_index = closest_index\n\n    while remaining_distance > 0 and current_index < len(path.poses) - 1:\n        segment_start = path.poses[current_index].pose\n        segment_end = path.poses[current_index + 1].pose\n\n        # Compute Euclidean distance between segment_start and segment_end.\n        dx = segment_end.position.x - segment_start.position.x\n        dy = segment_end.position.y - segment_start.position.y\n        dz = segment_end.position.z - segment_start.position.z\n        segment_distance = np.linalg.norm(np.array([dx, dy, dz]))\n\n        # Skip zero-length segments\n        if segment_distance < ZERO_DISTANCE_TOLERANCE:\n            current_index += 1\n            continue\n\n        # If we can place target on this segment\n        if remaining_distance <= segment_distance:\n            ratio = remaining_distance / segment_distance\n            dynamic_target_pose = PoseStamped()\n            dynamic_target_pose.header = path.header\n            dynamic_target_pose.pose.position.x = segment_start.position.x + ratio * dx\n            dynamic_target_pose.pose.position.y = segment_start.position.y + ratio * dy\n            dynamic_target_pose.pose.position.z = segment_start.position.z + ratio * dz\n            # Use the orientation of the segment end.\n            dynamic_target_pose.pose.orientation = segment_end.orientation\n            return dynamic_target_pose\n\n        remaining_distance -= segment_distance  # Move to next segment\n        current_index += 1\n\n    # If we've consumed all segments, return last pose as target\n    return path.poses[-1]</code></pre><p>This calculator gifts us a dynamic frame that moves away from the robot as it moves but maintains its distance (1 meter). In this way, the coordination problem in the old system is eliminated because the dynamic frame now cares where the robot is. If the robot doesn't go anywhere, it doesn't continue on the path either. The robot follows the dynamic target, the dynamic target follows the route, and as a result, Taluy follows the route.</p><h3>Notes on the future</h3><p>Although our new navigation system is much more successful than the old one, it does not fully meet our needs. One of its biggest deficiencies is that it does not care about obstacles. That is, it does not have object avoidance. We will need this. Our next level navigation system is on the way.</p>",
        "slug": "auv-tying-carrot"
    },
    {
        "id": 14,
        "title": "AUV Social: Strengthening Our Team Spirit",
        "author": "Sena Gülek",
        "date": "2026-01-02",
        "sub_team": "Business Operations",
        "image": "images/blog/auv_sosyal1.jpeg",
        "content": "<p>As the ITU AUV Team, we don't just deal with technical work; we also dedicate quite a bit of time to social events to keep communication and motivation high within the team. Throughout the year, we held many events with all our sub-teams.</p><p>Bonding as a team is actually one of the biggest reasons behind our success in technical work. As our members get to know each other better and work in a comfortable environment, efficiency in projects naturally increases. That's why we organized a bunch of social activities during the year: We arranged social organizations like games specially designed for the team, sports events, and picnics. Thanks to these activities, our internal communication has strengthened, and we have further solidified our team spirit. We also had a professional photo shoot for our team's website and works.</p><p>These organizations, which strengthen team harmony, will continue to contribute to the work we will do throughout the season.</p>",
        "slug": "auv-social-team-spirit"
    }
]
